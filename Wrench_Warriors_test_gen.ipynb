{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Link to one of the used datasets: https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt"
      ],
      "metadata": {
        "id": "3r9kRhdrMH7Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQiQYLnhMEfW",
        "outputId": "2acffa40-b219-4892-8181-87b8005ab1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')\n",
        "# Here, use the link of the database from which you want to take the responses."
      ],
      "metadata": {
        "id": "7OhTC-WdMmA_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.text[:1500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "HYxxyWgsNdZg",
        "outputId": "5b5ec4a3-6b2b-4011-8406-6df6f658ef9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is the 100th Etext file presented by Project Gutenberg, and\\nis presented in cooperation with World Library, Inc., from their\\nLibrary of the Future and Shakespeare CDROMS.  Project Gutenberg\\noften releases Etexts that are NOT placed in the Public Domain!!\\n\\nShakespeare\\n\\n*This Etext has certain copyright implications you should read!*\\n\\n<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\\nPROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\\nWITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\\nDISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS\\nPERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\\nCOMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\\nSERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\\n\\n*Project Gutenberg is proud to cooperate with The World Library*\\nin the presentation of The Complete Works of William Shakespeare\\nfor your reading for education and entertainment.  HOWEVER, THIS\\nIS NEITHER SHAREWARE NOR PUBLIC DOMAIN. . .AND UNDER THE LIBRARY\\nOF THE FUTURE CONDITIONS OF THIS PRESENTATION. . .NO CHARGES MAY\\nBE MADE FOR *ANY* ACCESS TO THIS MATERIAL.  YOU ARE ENCOURAGED!!\\nTO GIVE IT AWAY TO ANYONE YOU LIKE, BUT NO CHARGES ARE ALLOWED!!\\n\\n\\n**Welcome To The World of Free Plain Vanilla Electronic Texts**\\n\\n**Etexts Readable By Both Humans and By Computers, Since 1971**\\n\\n*These Etexts Prepared By Hundreds of Volunteers and Donations*\\n\\nInforma'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = response.text.split('\\n')\n",
        "data[0]\n",
        "# Splitting according to each line. Take into consideration from where the data in the actual file starts from."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5gOAAB9hNma3",
        "outputId": "7b97f423-56ee-433d-a278-e8d9ee9168ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is the 100th Etext file presented by Project Gutenberg, and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = \" \".join(data)\n",
        "data[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "FLdilTzTNtCn",
        "outputId": "982a56f1-cc8d-451d-827b-d5421452bb83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is the 100th Etext file presented by Project Gutenberg, and is presented in cooperation with World Library, Inc., from their Library of the Future and Shakespeare CDROMS.  Project Gutenberg often releases Etexts that are NOT placed in the Public Domain!!  Shakespeare  *This Etext has certain copyright implications you should read!*  <<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM SHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS PROVIDED BY PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE DISTRIBUTED SO LONG AS SUCH COPIES (1) ARE FOR YOUR OR OTHERS PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY SERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>  *Project Gutenberg is proud to cooperate with The World Library* in the presentation of The Complete Works of William Shakespeare for your reading for educatio'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(doc):\n",
        "  tokens = doc.split()\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "tokens = clean_text(data)\n",
        "print(tokens[:50])\n",
        "print(len(tokens))\n",
        "print(len(set(tokens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8UeMjKrOEB_",
        "outputId": "eec0ad69-95e4-4543-8d8e-d5cc8d88c3c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'is', 'the', 'etext', 'file', 'presented', 'by', 'project', 'gutenberg', 'and', 'is', 'presented', 'in', 'cooperation', 'with', 'world', 'library', 'inc', 'from', 'their', 'library', 'of', 'the', 'future', 'and', 'shakespeare', 'cdroms', 'project', 'gutenberg', 'often', 'releases', 'etexts', 'that', 'are', 'not', 'placed', 'in', 'the', 'public', 'domain', 'shakespeare', 'this', 'etext', 'has', 'certain', 'copyright', 'implications', 'you', 'should', 'read']\n",
            "899788\n",
            "28113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " use a set of previous words to predict the next word in the sentence. To be precise we are going to use a set of 50 words to predict the 51st word. Hence we are going to divide our data in chunks of 51 words and at the last we will separate the last word from every line. We are going to limit our dataset to 200000 words."
      ],
      "metadata": {
        "id": "1W8IMkXiRrKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 200000:\n",
        "    break\n",
        "\n",
        "print(len(lines))\n",
        "print(lines[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP8j3rUERkY4",
        "outputId": "160aec2d-5efc-4b65-e5a2-cfd3556baed2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "199951\n",
            "this is the etext file presented by project gutenberg and is presented in cooperation with world library inc from their library of the future and shakespeare cdroms project gutenberg often releases etexts that are not placed in the public domain shakespeare this etext has certain copyright implications you should read this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens[50])\n",
        "print(lines[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpInZLjljeqs",
        "outputId": "1e0a1b01-98c4-4982-9d8f-3623a92966d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this\n",
            "is the etext file presented by project gutenberg and is presented in cooperation with world library inc from their library of the future and shakespeare cdroms project gutenberg often releases etexts that are not placed in the public domain shakespeare this etext has certain copyright implications you should read this electronic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Y2MXkeYhjrJc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to create a unique numerical token for each unique word in the dataset. fit_on_texts() updates internal vocabulary based on a list of texts. texts_to_sequences() transforms each text in texts to a sequence of integers."
      ],
      "metadata": {
        "id": "X4HaSAv8jxq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "metadata": {
        "id": "If8HAXBvjt1M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sequences containes a list of integer values created by tokenizer. Each line in sequences has 51 words. Now we will split each line such that the first 50 words are in X and the last word is in y."
      ],
      "metadata": {
        "id": "FPeObo0WkBxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]\n",
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X0xM5twkCPr",
        "outputId": "94cb64b1-ea02-4534-ee39-f1756989459f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   22,    11,     1,   397,  2006,  6743,    30,   398,   455,\n",
              "           2,    11,  6743,    10,  6744,    15,   122,   486,   520,\n",
              "          47,    65,   486,     5,     1,  2775,     2,   418, 13163,\n",
              "         398,   455,   678, 13162,  2187,     9,    33,    12,  4811,\n",
              "          10,     1,   848,  3823,   418,    22,   397,   236,   611,\n",
              "         485, 13161,     6,    86,   610])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vocab_size contains all the uniques words in the dataset. tokenizer.word_index gives the mapping of each unique word to its numerical equivalent. Hence len() of tokenizer.word_index gives the vocab_size."
      ],
      "metadata": {
        "id": "kUAMRjpInMcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWx_F9QwnNnp",
        "outputId": "c3dd8376-230b-4463-81ca-a305eb719c25"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the LSTM Model:"
      ],
      "metadata": {
        "id": "o5uh595VnZnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RRYaqkDnWqw",
        "outputId": "55802d67-f9b2-4a5d-f25a-d7efa03bbacf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 50)            658250    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50, 100)           60400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13165)             1329665   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2138815 (8.16 MB)\n",
            "Trainable params: 2138815 (8.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trianing and running the model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "s46k_5JKnpwO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting: making the prediction\n",
        "model.fit(X, y, batch_size = 256, epochs = 100)"
      ],
      "metadata": {
        "id": "5N84N67OnyRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text=lines[12343]\n",
        "seed_text"
      ],
      "metadata": {
        "id": "3Oy0_t9HoPk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate_text_seq() generates n_words number of words after the given seed_text. We are going to pre-process the seed_text before predicting. We are going to encode the seed_text using the same encoding used for encoding the training data. Then we are going to convert the seed_textto 50 words by using pad_sequences(). Now we will predict using model.predict_classes(). After that we will search the word in tokenizer using the index in y_predict. Finally we will append the predicted word to seed_text and text and repeat the process."
      ],
      "metadata": {
        "id": "HhQt4J5moX9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)"
      ],
      "metadata": {
        "id": "2tzeqbK1oY2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next 100 words will be predicted\n",
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)"
      ],
      "metadata": {
        "id": "O-0T1qNMod-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}